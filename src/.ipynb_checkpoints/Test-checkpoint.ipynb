{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data as tdata\n",
    "import numpy as np\n",
    "\n",
    "import ref\n",
    "from datasets.h36m import H36M\n",
    "from datasets.mpii import MPII\n",
    "#TODO: write the LSTM\n",
    "from models import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'progress'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-96fe0a85b431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'progress'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from progress.bar import Bar\n",
    "\n",
    "import ref\n",
    "from utils.utils import AverageMeter\n",
    "from utils.eval import Accuracy, getPreds, MPJPE\n",
    "from utils.debugger import Debugger\n",
    "from models.layers.FusionCriterion import FusionCriterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic step for train or evaluation\n",
    "def step(split, epoch, opt, dataLoader, model, criterion, optimizer = None):\n",
    "  # Choose the mode\n",
    "  ## Train mode \n",
    "  if split == 'train':\n",
    "    model.train()\n",
    "  ## Evaluate mode(Normally without Dropout and BatchNorm)\n",
    "  else:\n",
    "    model.eval()\n",
    "  # Load default values\n",
    "  Loss, Acc, Mpjpe, Loss3D = AverageMeter(), AverageMeter(), AverageMeter(), AverageMeter()\n",
    "  # Show iteration as bar\n",
    "  nIters = len(dataLoader)\n",
    "  bar = Bar('==>', max=nIters)\n",
    "  # Loop in dataloader\n",
    "  for i, (input, target2D, target3D, meta) in enumerate(dataLoader):\n",
    "    ## Wraps tensors and records the operations applied to it\n",
    "    input_var = torch.autograd.Variable(input).float().cuda()\n",
    "    target2D_var = torch.autograd.Variable(target2D).float().cuda()\n",
    "    target3D_var = torch.autograd.Variable(target3D).float().cuda()\n",
    "    ## Forwad propagation\n",
    "    output = model(input_var)\n",
    "    ## Number of hourglasses to stack from parsed options(default 2)\n",
    "    reg = output[opt.nStack]\n",
    "    ## Debug level >= 2\n",
    "    if opt.DEBUG >= 2:\n",
    "      gt = getPreds(target2D.cpu().numpy()) * 4\n",
    "      pred = getPreds((output[opt.nStack - 1].data).cpu().numpy()) * 4\n",
    "      debugger = Debugger()\n",
    "      debugger.addImg((input[0].numpy().transpose(1, 2, 0)*256).astype(np.uint8))\n",
    "      debugger.addPoint2D(pred[0], (255, 0, 0))\n",
    "      debugger.addPoint2D(gt[0], (0, 0, 255))\n",
    "      debugger.showImg()\n",
    "      debugger.saveImg('debug/{}.png'.format(i))\n",
    "    # Fuse the criterion\n",
    "    loss = FusionCriterion(opt.regWeight, opt.varWeight)(reg, target3D_var)\n",
    "    # Update the 3D loss\n",
    "    Loss3D.update(loss.data[0], input.size(0))\n",
    "    for k in range(opt.nStack):\n",
    "      loss += criterion(output[k], target2D_var)\n",
    "\n",
    "    Loss.update(loss.data[0], input.size(0))\n",
    "    Acc.update(Accuracy((output[opt.nStack - 1].data).cpu().numpy(), (target2D_var.data).cpu().numpy()))\n",
    "    mpjpe, num3D = MPJPE((output[opt.nStack - 1].data).cpu().numpy(), (reg.data).cpu().numpy(), meta)\n",
    "    if num3D > 0:\n",
    "      Mpjpe.update(mpjpe, num3D)\n",
    "    if split == 'train':\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    " \n",
    "    Bar.suffix = '{split} Epoch: [{0}][{1}/{2}]| Total: {total:} | ETA: {eta:} | Loss {loss.avg:.6f} | Loss3D {loss3d.avg:.6f} \\\n",
    "                  | Acc {Acc.avg:.6f} | Mpjpe {Mpjpe.avg:.6f} ({Mpjpe.val:.6f})'.format(epoch, i, nIters, \\\n",
    "                  total=bar.elapsed_td, eta=bar.eta_td, loss=Loss, Acc=Acc, split = split, Mpjpe=Mpjpe, loss3d = Loss3D)\n",
    "    bar.next()\n",
    "\n",
    "  bar.finish()\n",
    "  return Loss.avg, Acc.avg, Mpjpe.avg, Loss3D.avg\n",
    "  \n",
    "\n",
    "def train(epoch, opt, train_loader, model, criterion, optimizer):\n",
    "  return step('train', epoch, opt, train_loader, model, criterion, optimizer)\n",
    "  \n",
    "def val(epoch, opt, val_loader, model, criterion):\n",
    "  return step('val', epoch, opt, val_loader, model, criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data as tdata\n",
    "import numpy as np\n",
    "\n",
    "import ref\n",
    "from datasets.h36m import H36M\n",
    "from datasets.mpii import MPII\n",
    "#TODO: write the LSTM\n",
    "from models import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adjust images to \n",
    "# Set training dataloader\n",
    "train_loader = tdata.DataLoader(\n",
    "    H36M(opt, 'train'), \n",
    "    batch_size = 1, \n",
    "    shuffle = False,\n",
    "    num_workers = int(ref.nThreads)\n",
    ")\n",
    "# Set validation dataloader\n",
    "val_loader = tdata.DataLoader(\n",
    "    H36M(opt, 'val'), \n",
    "    batch_size = 1, \n",
    "    shuffle = False,\n",
    "    num_workers = int(ref.nThreads)\n",
    ")\n",
    "    \n",
    "# Load Model\n",
    "model = LSTM().cuda()\n",
    "# Set the Criterion and Optimizer\n",
    "criterion = torch.nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), opt.LR, \n",
    "                                alpha = ref.alpha, \n",
    "                                eps = ref.epsilon, \n",
    "                                weight_decay = ref.weightDecay, \n",
    "                                momentum = ref.momentum)\n",
    "# Train and Eval\n",
    "for epoch in range(1, opt.nEpochs + 1):\n",
    "    ## Train the model\n",
    "    loss_train, acc_train, mpjpe_train, loss3d_train = train(epoch, opt, train_loader, model, criterion, optimizer)\n",
    "    ## Show results\n",
    "    f\"loss_train: {loss_train} | acc_train: {acc_train} | mpjpe_train: {mpjpe_train}\\n\"\n",
    "    ## Intervals to show eval results\n",
    "    if epoch % opt.valIntervals == 0:\n",
    "        ### Validation\n",
    "        loss_val, acc_val, mpjpe_val, loss3d_val = val(epoch, opt, val_loader, model, criterion)\n",
    "        f\"loss_train: {loss_train} | acc_train: {acc_train} | mpjpe_train: {mpjpe_train}\\n\"\n",
    "        ### Update the model\n",
    "        torch.save(model, os.path.join(opt.saveDir, f\"model_{epoch}.pth\"))\n",
    "        ## TODO: change the adjust_learning_rate\n",
    "        ## Use the optimizer to adjust learning rate\n",
    "        #adjust_learning_rate(optimizer, epoch, opt.dropLR, opt.LR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
